{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import LeakyReLU, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('Data/emnist-letters-test.csv', header = None)\n",
    "data_train = pd.read_csv('Data/emnist-letters-train.csv', header = None)\n",
    "\n",
    "X_train = data_train.drop(0, axis = 1)\n",
    "y_train = data_train[0].values\n",
    "X_test = data_test.drop(0, axis = 1)\n",
    "y_test = data_test[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return x.reshape(-1,28,28,1,order='F')/255.0\n",
    "\n",
    "X_train_preprocessed = preprocess(X_train.values)\n",
    "X_test_preprocessed = preprocess(X_test.values)\n",
    "\n",
    "label_enc = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "cv_train_scores = []\n",
    "cv_test_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7627 - loss: 0.7513 - val_accuracy: 0.7601 - val_loss: 0.7631\n",
      "Epoch 2/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4914 - val_accuracy: 0.7305 - val_loss: 0.8854\n",
      "Epoch 3/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 0.4450 - val_accuracy: 0.7741 - val_loss: 0.7144\n",
      "Epoch 4/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8599 - loss: 0.4214 - val_accuracy: 0.6983 - val_loss: 1.0442\n",
      "Epoch 5/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.4042 - val_accuracy: 0.7274 - val_loss: 0.9088\n",
      "Epoch 6/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.3893 - val_accuracy: 0.7496 - val_loss: 0.8229\n",
      "Epoch 7/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3811 - val_accuracy: 0.6680 - val_loss: 1.1236\n",
      "Epoch 8/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3662 - val_accuracy: 0.6024 - val_loss: 1.4571\n",
      "Epoch 9/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3629 - val_accuracy: 0.7084 - val_loss: 0.9472\n",
      "Epoch 10/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8783 - loss: 0.3578 - val_accuracy: 0.7597 - val_loss: 0.7502\n",
      "Epoch 11/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.3562 - val_accuracy: 0.7987 - val_loss: 0.6446\n",
      "Epoch 12/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3473 - val_accuracy: 0.7235 - val_loss: 0.9192\n",
      "Epoch 13/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.3445 - val_accuracy: 0.7731 - val_loss: 0.7516\n",
      "Epoch 14/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.3361 - val_accuracy: 0.7831 - val_loss: 0.6968\n",
      "Epoch 15/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3401 - val_accuracy: 0.6285 - val_loss: 1.2326\n",
      "Epoch 16/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.3336 - val_accuracy: 0.7815 - val_loss: 0.6938\n",
      "Epoch 17/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3305 - val_accuracy: 0.7815 - val_loss: 0.6655\n",
      "Epoch 18/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.3257 - val_accuracy: 0.8005 - val_loss: 0.6624\n",
      "Epoch 19/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.3275 - val_accuracy: 0.7868 - val_loss: 0.6828\n",
      "Epoch 20/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.3223 - val_accuracy: 0.7462 - val_loss: 0.8150\n",
      "Epoch 21/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.3194 - val_accuracy: 0.6517 - val_loss: 1.1970\n",
      "Epoch 22/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3250 - val_accuracy: 0.7782 - val_loss: 0.7116\n",
      "Epoch 23/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8875 - loss: 0.3228 - val_accuracy: 0.8187 - val_loss: 0.5803\n",
      "Epoch 24/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.3174 - val_accuracy: 0.7241 - val_loss: 0.9080\n",
      "Epoch 25/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.3156 - val_accuracy: 0.7671 - val_loss: 0.7412\n",
      "Epoch 1/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.7633 - val_accuracy: 0.7443 - val_loss: 0.8042\n",
      "Epoch 2/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.4899 - val_accuracy: 0.7356 - val_loss: 0.8848\n",
      "Epoch 3/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.4439 - val_accuracy: 0.7264 - val_loss: 0.8922\n",
      "Epoch 4/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 0.4156 - val_accuracy: 0.7558 - val_loss: 0.8131\n",
      "Epoch 5/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3991 - val_accuracy: 0.7852 - val_loss: 0.6869\n",
      "Epoch 6/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8717 - loss: 0.3830 - val_accuracy: 0.7397 - val_loss: 0.8714\n",
      "Epoch 7/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.3717 - val_accuracy: 0.7115 - val_loss: 0.9755\n",
      "Epoch 8/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.3640 - val_accuracy: 0.8034 - val_loss: 0.6236\n",
      "Epoch 9/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8780 - loss: 0.3596 - val_accuracy: 0.7626 - val_loss: 0.7868\n",
      "Epoch 10/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.3538 - val_accuracy: 0.7930 - val_loss: 0.6528\n",
      "Epoch 11/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8821 - loss: 0.3480 - val_accuracy: 0.7884 - val_loss: 0.6814\n",
      "Epoch 12/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8818 - loss: 0.3457 - val_accuracy: 0.7899 - val_loss: 0.6784\n",
      "Epoch 13/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8834 - loss: 0.3403 - val_accuracy: 0.7170 - val_loss: 0.9246\n",
      "Epoch 14/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.3342 - val_accuracy: 0.7493 - val_loss: 0.8099\n",
      "Epoch 15/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3373 - val_accuracy: 0.7605 - val_loss: 0.7919\n",
      "Epoch 16/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.3300 - val_accuracy: 0.7158 - val_loss: 0.9238\n",
      "Epoch 17/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8866 - loss: 0.3273 - val_accuracy: 0.8126 - val_loss: 0.6142\n",
      "Epoch 18/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8888 - loss: 0.3240 - val_accuracy: 0.7639 - val_loss: 0.7714\n",
      "Epoch 19/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8892 - loss: 0.3229 - val_accuracy: 0.7409 - val_loss: 0.8333\n",
      "Epoch 20/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.3223 - val_accuracy: 0.7522 - val_loss: 0.7992\n",
      "Epoch 21/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3211 - val_accuracy: 0.7777 - val_loss: 0.7205\n",
      "Epoch 22/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.3236 - val_accuracy: 0.7970 - val_loss: 0.6455\n",
      "Epoch 23/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3160 - val_accuracy: 0.6579 - val_loss: 1.1351\n",
      "Epoch 24/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3134 - val_accuracy: 0.7923 - val_loss: 0.6615\n",
      "Epoch 25/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8920 - loss: 0.3107 - val_accuracy: 0.8140 - val_loss: 0.6172\n",
      "Epoch 1/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7611 - loss: 0.7602 - val_accuracy: 0.7708 - val_loss: 0.7071\n",
      "Epoch 2/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 0.4920 - val_accuracy: 0.6998 - val_loss: 0.9475\n",
      "Epoch 3/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.4449 - val_accuracy: 0.7013 - val_loss: 0.9663\n",
      "Epoch 4/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.4176 - val_accuracy: 0.6820 - val_loss: 1.0457\n",
      "Epoch 5/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8679 - loss: 0.4039 - val_accuracy: 0.6698 - val_loss: 1.1087\n",
      "Epoch 6/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.3919 - val_accuracy: 0.5858 - val_loss: 1.4251\n",
      "Epoch 7/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.3790 - val_accuracy: 0.5776 - val_loss: 1.4417\n",
      "Epoch 8/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3688 - val_accuracy: 0.7607 - val_loss: 0.7750\n",
      "Epoch 9/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.3663 - val_accuracy: 0.6580 - val_loss: 1.1792\n",
      "Epoch 10/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.3552 - val_accuracy: 0.7477 - val_loss: 0.8254\n",
      "Epoch 11/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.3553 - val_accuracy: 0.6635 - val_loss: 1.1032\n",
      "Epoch 12/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.3463 - val_accuracy: 0.6986 - val_loss: 1.0191\n",
      "Epoch 13/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.3465 - val_accuracy: 0.7012 - val_loss: 0.9831\n",
      "Epoch 14/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.3363 - val_accuracy: 0.7642 - val_loss: 0.7549\n",
      "Epoch 15/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.3401 - val_accuracy: 0.7220 - val_loss: 0.9288\n",
      "Epoch 16/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.3359 - val_accuracy: 0.7730 - val_loss: 0.7254\n",
      "Epoch 17/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.3319 - val_accuracy: 0.7271 - val_loss: 0.8796\n",
      "Epoch 18/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.3278 - val_accuracy: 0.7488 - val_loss: 0.7932\n",
      "Epoch 19/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3257 - val_accuracy: 0.7148 - val_loss: 0.9312\n",
      "Epoch 20/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.3221 - val_accuracy: 0.6620 - val_loss: 1.1242\n",
      "Epoch 21/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3249 - val_accuracy: 0.7118 - val_loss: 0.9369\n",
      "Epoch 22/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3207 - val_accuracy: 0.6976 - val_loss: 0.9661\n",
      "Epoch 23/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.3196 - val_accuracy: 0.7075 - val_loss: 0.9796\n",
      "Epoch 24/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3159 - val_accuracy: 0.6959 - val_loss: 1.0203\n",
      "Epoch 25/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.3178 - val_accuracy: 0.6743 - val_loss: 1.0595\n",
      "Epoch 1/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7618 - loss: 0.7549 - val_accuracy: 0.7707 - val_loss: 0.7181\n",
      "Epoch 2/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.4903 - val_accuracy: 0.7840 - val_loss: 0.6634\n",
      "Epoch 3/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 0.4461 - val_accuracy: 0.7785 - val_loss: 0.7162\n",
      "Epoch 4/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 0.4193 - val_accuracy: 0.7544 - val_loss: 0.7906\n",
      "Epoch 5/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8661 - loss: 0.3999 - val_accuracy: 0.7688 - val_loss: 0.7128\n",
      "Epoch 6/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8694 - loss: 0.3867 - val_accuracy: 0.7292 - val_loss: 0.8787\n",
      "Epoch 7/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.3771 - val_accuracy: 0.7507 - val_loss: 0.7981\n",
      "Epoch 8/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3668 - val_accuracy: 0.7419 - val_loss: 0.8264\n",
      "Epoch 9/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3604 - val_accuracy: 0.7888 - val_loss: 0.6645\n",
      "Epoch 10/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.3560 - val_accuracy: 0.7729 - val_loss: 0.7201\n",
      "Epoch 11/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8794 - loss: 0.3550 - val_accuracy: 0.7485 - val_loss: 0.7945\n",
      "Epoch 12/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.3492 - val_accuracy: 0.6785 - val_loss: 1.0747\n",
      "Epoch 13/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8822 - loss: 0.3454 - val_accuracy: 0.7389 - val_loss: 0.8595\n",
      "Epoch 14/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.3343 - val_accuracy: 0.7204 - val_loss: 0.9287\n",
      "Epoch 15/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8862 - loss: 0.3346 - val_accuracy: 0.7448 - val_loss: 0.7864\n",
      "Epoch 16/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8831 - loss: 0.3381 - val_accuracy: 0.8130 - val_loss: 0.5731\n",
      "Epoch 17/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.3338 - val_accuracy: 0.8098 - val_loss: 0.6248\n",
      "Epoch 18/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8877 - loss: 0.3293 - val_accuracy: 0.7970 - val_loss: 0.6528\n",
      "Epoch 19/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.3288 - val_accuracy: 0.7830 - val_loss: 0.7039\n",
      "Epoch 20/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8881 - loss: 0.3258 - val_accuracy: 0.7849 - val_loss: 0.6929\n",
      "Epoch 21/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.3254 - val_accuracy: 0.7248 - val_loss: 0.9173\n",
      "Epoch 22/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.3185 - val_accuracy: 0.7708 - val_loss: 0.7145\n",
      "Epoch 23/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.3237 - val_accuracy: 0.7861 - val_loss: 0.6678\n",
      "Epoch 24/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3172 - val_accuracy: 0.8317 - val_loss: 0.5475\n",
      "Epoch 25/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8911 - loss: 0.3150 - val_accuracy: 0.7011 - val_loss: 0.9409\n",
      "Epoch 1/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7596 - loss: 0.7654 - val_accuracy: 0.7829 - val_loss: 0.6910\n",
      "Epoch 2/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 0.4928 - val_accuracy: 0.7610 - val_loss: 0.7507\n",
      "Epoch 3/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 0.4432 - val_accuracy: 0.7352 - val_loss: 0.8520\n",
      "Epoch 4/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.4149 - val_accuracy: 0.6947 - val_loss: 1.0274\n",
      "Epoch 5/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8688 - loss: 0.3972 - val_accuracy: 0.7195 - val_loss: 0.9535\n",
      "Epoch 6/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.3849 - val_accuracy: 0.7101 - val_loss: 0.9595\n",
      "Epoch 7/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8731 - loss: 0.3793 - val_accuracy: 0.6434 - val_loss: 1.2454\n",
      "Epoch 8/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8766 - loss: 0.3675 - val_accuracy: 0.7386 - val_loss: 0.8717\n",
      "Epoch 9/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.3619 - val_accuracy: 0.6871 - val_loss: 1.0583\n",
      "Epoch 10/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8787 - loss: 0.3587 - val_accuracy: 0.7459 - val_loss: 0.8199\n",
      "Epoch 11/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.3502 - val_accuracy: 0.8002 - val_loss: 0.6349\n",
      "Epoch 12/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.3458 - val_accuracy: 0.7670 - val_loss: 0.7546\n",
      "Epoch 13/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8824 - loss: 0.3444 - val_accuracy: 0.7061 - val_loss: 0.9516\n",
      "Epoch 14/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8847 - loss: 0.3371 - val_accuracy: 0.7576 - val_loss: 0.7888\n",
      "Epoch 15/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3362 - val_accuracy: 0.6919 - val_loss: 1.0202\n",
      "Epoch 16/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3336 - val_accuracy: 0.7607 - val_loss: 0.7807\n",
      "Epoch 17/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.3275 - val_accuracy: 0.6623 - val_loss: 1.1359\n",
      "Epoch 18/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3248 - val_accuracy: 0.7309 - val_loss: 0.9051\n",
      "Epoch 19/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3264 - val_accuracy: 0.7604 - val_loss: 0.7799\n",
      "Epoch 20/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3283 - val_accuracy: 0.7722 - val_loss: 0.7384\n",
      "Epoch 21/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.3186 - val_accuracy: 0.7385 - val_loss: 0.8192\n",
      "Epoch 22/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.3169 - val_accuracy: 0.7504 - val_loss: 0.8055\n",
      "Epoch 23/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.3181 - val_accuracy: 0.8002 - val_loss: 0.6533\n",
      "Epoch 24/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.3146 - val_accuracy: 0.6807 - val_loss: 1.0682\n",
      "Epoch 25/25\n",
      "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.3115 - val_accuracy: 0.7506 - val_loss: 0.8128\n",
      "Average Training Accuracy: 0.7577364921569825\n",
      "Average Validation Accuracy: 0.7414301753044128\n",
      "Test Accuracy: 0.7170946002006531\n"
     ]
    }
   ],
   "source": [
    "for train_index, val_index in kf.split(X_train_preprocessed):\n",
    "    X_train_fold, X_val = X_train_preprocessed[train_index], X_train_preprocessed[val_index]\n",
    "    y_train_fold, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    y_train_fold_tensor = tf.convert_to_tensor(label_enc.fit_transform(y_train_fold.reshape(-1, 1)))\n",
    "    y_val_tensor = tf.convert_to_tensor(label_enc.transform(y_val.reshape(-1, 1)))\n",
    "\n",
    "    X_train_tensor = tf.convert_to_tensor(X_train_fold)\n",
    "    X_val_tensor = tf.convert_to_tensor(X_val)\n",
    "\n",
    "    model = Sequential()\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),        \n",
    "    Conv2D(32, kernel_size=(3, 3)),\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # for downsizing the info from the features a bit\n",
    "    model.add(Dropout(0.25)) # to prevent having dead neurons\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "    model.add(LeakyReLU(negative_slope=0.1))\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "    opt = Adam(learning_rate=0.002)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.fit(X_train_tensor, y_train_fold_tensor, epochs=25, batch_size=32, validation_data = (X_val_tensor, y_val_tensor), verbose=1)\n",
    "\n",
    "    # Evaluate the model on the training data\n",
    "    train_score = model.evaluate(X_train_tensor, y_train_fold_tensor, verbose=0)[1]\n",
    "    cv_train_scores.append(train_score)\n",
    "\n",
    "    # Evaluate the model on the validation data\n",
    "    val_score = model.evaluate(X_val_tensor, y_val_tensor, verbose=0)[1]\n",
    "    cv_test_scores.append(val_score)\n",
    "\n",
    "average_train_score = np.mean(cv_train_scores)\n",
    "average_val_score = np.mean(cv_test_scores)\n",
    "print(f'Average Training Accuracy: {average_train_score}')\n",
    "print(f'Average Validation Accuracy: {average_val_score}')\n",
    "\n",
    "\n",
    "X_test_tensor = tf.convert_to_tensor(X_test_preprocessed)\n",
    "y_test_tensor = tf.convert_to_tensor(label_enc.transform(y_test.reshape(-1, 1)))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_tensor, y_test_tensor, verbose=0)\n",
    "print(f'Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
